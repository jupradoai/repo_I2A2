import streamlit as st
import google.generativeai as genai
from dotenv import load_dotenv
import os
import json
import pandas as pd
from zipfile import ZipFile
import io
from pydantic import BaseModel, Field, validator
from typing import Dict, List, Any, Optional
from datetime import datetime
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Modelos Pydantic para valida√ß√£o de dados
class DadosCSV(BaseModel):
    """Modelo para valida√ß√£o de dados CSV"""
    nome_arquivo: str
    registros: List[Dict[str, Any]]
    total_registros: int
    colunas: List[str]
    tipos_dados: Dict[str, str]
    timestamp_processamento: datetime = Field(default_factory=datetime.now)
    
    @validator('registros')
    def validar_registros(cls, v):
        if not v:
            raise ValueError('Lista de registros n√£o pode estar vazia')
        return v
    
    @validator('total_registros')
    def validar_total_registros(cls, v, values):
        if 'registros' in values and v != len(values['registros']):
            raise ValueError('Total de registros n√£o corresponde ao n√∫mero real de registros')
        return v

class AnaliseDados(BaseModel):
    """Modelo para estrutura√ß√£o da an√°lise de dados"""
    pergunta_usuario: str
    interpretacao: str
    dados_analisados: List[str]
    calculos_realizados: List[str]
    resultado: str
    confianca: float = Field(ge=0.0, le=1.0)
    timestamp_analise: datetime = Field(default_factory=datetime.now)
    
    @validator('confianca')
    def validar_confianca(cls, v):
        if not 0.0 <= v <= 1.0:
            raise ValueError('Confian√ßa deve estar entre 0.0 e 1.0')
        return v

class DadosProcessados(BaseModel):
    """Modelo para valida√ß√£o dos dados processados"""
    arquivos: Dict[str, DadosCSV]
    total_arquivos: int
    timestamp_processamento: datetime = Field(default_factory=datetime.now)
    
    @validator('total_arquivos')
    def validar_total_arquivos(cls, v, values):
        if 'arquivos' in values and v != len(values['arquivos']):
            raise ValueError('Total de arquivos n√£o corresponde ao n√∫mero real de arquivos')
        return v

# Carregar vari√°veis de ambiente
load_dotenv()

# Configurar o Gemini
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
genai.configure(api_key=GOOGLE_API_KEY)

# Configurar o modelo
model = genai.GenerativeModel('gemini-2.0-flash')

# Sistema de prompts estruturados para respostas mais objetivas
class SistemaPrompts:
    """Sistema de prompts estruturados para an√°lises mais objetivas"""
    
    @staticmethod
    def prompt_analise_estatistica():
        return """
        Voc√™ √© um analista de dados especializado. Responda de forma OBJETIVA e PRECISA.
        
        ESTRUTURA OBRIGAT√ìRIA da resposta:
        
        ## üìä AN√ÅLISE ESTAT√çSTICA
        
        **Pergunta:** [pergunta do usu√°rio]
        
        **Dados Analisados:** [arquivos e registros utilizados]
        
        **M√©tricas Encontradas:**
        - [m√©trica 1]: [valor num√©rico]
        - [m√©trica 2]: [valor num√©rico]
        
        **Conclus√£o:** [resposta direta e objetiva em 1-2 frases]
        
        **Confian√ßa:** [0-100%] - [justificativa breve]
        
        REGRAS:
        - Use APENAS dados fornecidos
        - Seja CONCISO e DIRETO
        - Evite linguagem vaga
        - Sempre forne√ßa valores num√©ricos quando poss√≠vel
        - M√°ximo 3 par√°grafos
        """
    
    @staticmethod
    def prompt_analise_tendencia():
        return """
        Voc√™ √© um analista de tend√™ncias. Identifique padr√µes de forma OBJETIVA.
        
        ESTRUTURA OBRIGAT√ìRIA:
        
        ## üìà AN√ÅLISE DE TEND√äNCIAS
        
        **Padr√£o Identificado:** [descri√ß√£o clara do padr√£o]
        
        **Evid√™ncias:**
        - [evid√™ncia 1 com dados]
        - [evid√™ncia 2 com dados]
        
        **For√ßa da Tend√™ncia:** [Forte/M√©dia/Fraca] - [justificativa]
        
        **Conclus√£o:** [resposta direta]
        
        REGRAS:
        - Baseie-se APENAS nos dados
        - Quantifique quando poss√≠vel
        - Seja espec√≠fico sobre a for√ßa da tend√™ncia
        """
    
    @staticmethod
    def prompt_comparacao():
        return """
        Voc√™ √© um analista comparativo. Compare dados de forma OBJETIVA.
        
        ESTRUTURA OBRIGAT√ìRIA:
        
        ## ‚öñÔ∏è AN√ÅLISE COMPARATIVA
        
        **Compara√ß√£o:** [o que est√° sendo comparado]
        
        **Diferen√ßas Principais:**
        1. [diferen√ßa 1 com valores]
        2. [diferen√ßa 2 com valores]
        
        **Conclus√£o:** [qual √© melhor/maior/menor e por qu√™]
        
        **Signific√¢ncia:** [Alta/M√©dia/Baixa] - [justificativa]
        
        REGRAS:
        - Sempre forne√ßa valores comparativos
        - Evite opini√µes pessoais
        - Use dados quantitativos
        """

# Fun√ß√£o para processar arquivos CSV dentro de um ZIP com valida√ß√£o Pydantic
def processar_arquivo_zip(arquivo_zip):
    """
    Processa arquivos CSV dentro de um ZIP com valida√ß√£o usando Pydantic
    """
    try:
        dados_arquivos = {}
        
        with ZipFile(arquivo_zip) as zip_file:
            arquivos_csv = [f for f in zip_file.namelist() if f.endswith('.csv')]
            
            if not arquivos_csv:
                raise ValueError("Nenhum arquivo CSV encontrado no ZIP")
            
            for arquivo in arquivos_csv:
                try:
                    with zip_file.open(arquivo) as csv_file:
                        df = pd.read_csv(csv_file)
                        
                        # Limitar a 1000 registros para performance
                        if len(df) > 1000:
                            df = df.sample(1000, random_state=42)
                            logger.info(f"Arquivo {arquivo} limitado a 1000 registros")
                        
                        # Criar inst√¢ncia validada do modelo DadosCSV
                        dados_csv = DadosCSV(
                            nome_arquivo=arquivo,
                            registros=df.to_dict(orient='records'),
                            total_registros=len(df),
                            colunas=df.columns.tolist(),
                            tipos_dados=df.dtypes.astype(str).to_dict()
                        )
                        
                        dados_arquivos[arquivo] = dados_csv
                        logger.info(f"Arquivo {arquivo} processado com sucesso: {len(df)} registros")
                        
                except Exception as e:
                    logger.error(f"Erro ao processar arquivo {arquivo}: {str(e)}")
                    st.error(f"Erro ao processar {arquivo}: {str(e)}")
                    continue
        
        # Criar inst√¢ncia validada do modelo DadosProcessados
        dados_processados = DadosProcessados(
            arquivos=dados_arquivos,
            total_arquivos=len(dados_arquivos)
        )
        
        logger.info(f"Processamento conclu√≠do: {len(dados_arquivos)} arquivos processados")
        return dados_processados
        
    except Exception as e:
        logger.error(f"Erro geral no processamento: {str(e)}")
        st.error(f"Erro no processamento: {str(e)}")
        return None

# Fun√ß√£o para gerar resposta baseada nos dados e na pergunta com valida√ß√£o Pydantic
def gerar_resposta(prompt, dados_contexto):
    """
    Gera resposta estruturada usando Pydantic para valida√ß√£o e prompts espec√≠ficos para objetividade
    """
    try:
        # Preparar dados para o contexto
        dados_para_analise = {}
        for nome_arquivo, dados_csv in dados_contexto.items():
            dados_para_analise[nome_arquivo] = {
                'registros': dados_csv.registros,
                'colunas': dados_csv.colunas,
                'tipos_dados': dados_csv.tipos_dados,
                'total_registros': dados_csv.total_registros
            }
        
        # Classificar o tipo de pergunta
        tipo_pergunta = classificar_pergunta(prompt)
        
        # Selecionar prompt espec√≠fico baseado no tipo de pergunta
        if tipo_pergunta == "estatistica":
            instrucao = SistemaPrompts.prompt_analise_estatistica()
        elif tipo_pergunta == "tendencia":
            instrucao = SistemaPrompts.prompt_analise_tendencia()
        elif tipo_pergunta == "comparacao":
            instrucao = SistemaPrompts.prompt_comparacao()
        else:
            instrucao = """
            Voc√™ √© um analista de dados especializado. Responda de forma OBJETIVA e PRECISA.
            
            ESTRUTURA OBRIGAT√ìRIA:
            
            ## üìä AN√ÅLISE DE DADOS
            
            **Pergunta:** [pergunta do usu√°rio]
            
            **Dados Analisados:** [arquivos e registros utilizados]
            
            **An√°lise:** [resposta direta e objetiva]
            
            **Conclus√£o:** [resumo em 1 frase]
            
            **Confian√ßa:** [0-100%]
            
            REGRAS:
            - Use APENAS dados fornecidos
            - Seja CONCISO e DIRETO
            - Evite linguagem vaga
            - Sempre forne√ßa valores num√©ricos quando poss√≠vel
            """
        
        contexto = f"{instrucao}\n\nDADOS DISPON√çVEIS: {json.dumps(dados_para_analise, ensure_ascii=False)}\n\nPERGUNTA: {prompt}"
        
        resposta = model.generate_content(contexto)
        
        # Calcular m√©tricas de qualidade
        qualidade = calcular_qualidade_resposta(resposta.text, dados_contexto)
        
        # Tentar estruturar a resposta usando Pydantic
        try:
            analise_estruturada = AnaliseDados(
                pergunta_usuario=prompt,
                interpretacao=f"An√°lise {tipo_pergunta} baseada em {len(dados_contexto)} arquivo(s)",
                dados_analisados=list(dados_contexto.keys()),
                calculos_realizados=[f"An√°lise {tipo_pergunta}", "Valida√ß√£o Pydantic"],
                resultado=resposta.text,
                confianca=qualidade['score'] / 100.0
            )
            
            # Retornar resposta estruturada com m√©tricas de qualidade
            return f"""
{analise_estruturada.resultado}

---
**üìä M√©tricas de Qualidade:**
- **Score:** {qualidade['score']}/100
- **N√∫meros Encontrados:** {qualidade['numeros_encontrados']}
- **Especificidade:** {qualidade['especificidade']}/6
- **Tipo de An√°lise:** {tipo_pergunta.title()}
- **Timestamp:** {analise_estruturada.timestamp_analise.strftime('%d/%m/%Y %H:%M:%S')}
            """
            
        except Exception as e:
            logger.warning(f"N√£o foi poss√≠vel estruturar a resposta: {str(e)}")
            return f"""
{resposta.text}

---
**üìä M√©tricas de Qualidade:**
- **Score:** {qualidade['score']}/100
- **N√∫meros Encontrados:** {qualidade['numeros_encontrados']}
- **Especificidade:** {qualidade['especificidade']}/6
- **Tipo de An√°lise:** {tipo_pergunta.title()}
            """
            
    except Exception as e:
        logger.error(f"Erro ao gerar resposta: {str(e)}")
        return f"Erro ao processar sua pergunta: {str(e)}"

# Fun√ß√£o para exportar dados validados em JSON
def exportar_dados_validados(dados_processados):
    """
    Exporta dados processados em formato JSON estruturado
    """
    try:
        dados_export = {
            "metadata": {
                "total_arquivos": dados_processados.total_arquivos,
                "timestamp_processamento": dados_processados.timestamp_processamento.isoformat(),
                "versao": "1.0"
            },
            "arquivos": {}
        }
        
        for nome_arquivo, dados_csv in dados_processados.arquivos.items():
            dados_export["arquivos"][nome_arquivo] = {
                "nome_arquivo": dados_csv.nome_arquivo,
                "total_registros": dados_csv.total_registros,
                "colunas": dados_csv.colunas,
                "tipos_dados": dados_csv.tipos_dados,
                "timestamp_processamento": dados_csv.timestamp_processamento.isoformat(),
                "registros": dados_csv.registros[:100]  # Limitar para exporta√ß√£o
            }
        
        return json.dumps(dados_export, ensure_ascii=False, indent=2)
        
    except Exception as e:
        logger.error(f"Erro ao exportar dados: {str(e)}")
        return None

# Fun√ß√£o para validar integridade dos dados
def validar_integridade_dados(dados_processados):
    """
    Valida a integridade dos dados processados
    """
    try:
        validacoes = []
        
        for nome_arquivo, dados_csv in dados_processados.arquivos.items():
            # Validar se o n√∫mero de registros est√° correto
            if len(dados_csv.registros) != dados_csv.total_registros:
                validacoes.append(f"‚ùå {nome_arquivo}: Inconsist√™ncia no n√∫mero de registros")
            else:
                validacoes.append(f"‚úÖ {nome_arquivo}: {dados_csv.total_registros} registros v√°lidos")
            
            # Validar se h√° colunas
            if not dados_csv.colunas:
                validacoes.append(f"‚ùå {nome_arquivo}: Nenhuma coluna encontrada")
            else:
                validacoes.append(f"‚úÖ {nome_arquivo}: {len(dados_csv.colunas)} colunas")
            
            # Validar se h√° dados
            if not dados_csv.registros:
                validacoes.append(f"‚ùå {nome_arquivo}: Nenhum registro encontrado")
            else:
                validacoes.append(f"‚úÖ {nome_arquivo}: Dados presentes")
        
        return validacoes
        
    except Exception as e:
        logger.error(f"Erro na valida√ß√£o: {str(e)}")
        return [f"‚ùå Erro na valida√ß√£o: {str(e)}"]

# Fun√ß√£o para classificar o tipo de pergunta
def classificar_pergunta(prompt):
    """
    Classifica o tipo de pergunta para usar o prompt mais adequado
    """
    prompt_lower = prompt.lower()
    
    # Palavras-chave para diferentes tipos de an√°lise
    estatisticas = ['m√©dia', 'mediana', 'moda', 'desvio', 'padr√£o', 'percentil', 'quartil', 'correla√ß√£o']
    tendencias = ['tend√™ncia', 'padr√£o', 'crescimento', 'diminui√ß√£o', 'evolu√ß√£o', 'comportamento']
    comparacoes = ['comparar', 'diferen√ßa', 'maior', 'menor', 'melhor', 'pior', 'versus', 'vs']
    
    if any(palavra in prompt_lower for palavra in estatisticas):
        return "estatistica"
    elif any(palavra in prompt_lower for palavra in tendencias):
        return "tendencia"
    elif any(palavra in prompt_lower for palavra in comparacoes):
        return "comparacao"
    else:
        return "geral"

# Fun√ß√£o para calcular m√©tricas de qualidade da resposta
def calcular_qualidade_resposta(resposta, dados_utilizados):
    """
    Calcula m√©tricas de qualidade da resposta
    """
    try:
        # Contar n√∫meros na resposta (indicador de precis√£o)
        import re
        numeros = len(re.findall(r'\d+\.?\d*', resposta))
        
        # Contar palavras espec√≠ficas de dados
        palavras_dados = ['m√©dia', 'mediana', 'total', 'percentual', 'correla√ß√£o', 'tend√™ncia']
        especificidade = sum(1 for palavra in palavras_dados if palavra.lower() in resposta.lower())
        
        # Calcular score de qualidade (0-100)
        score = min(100, (numeros * 10) + (especificidade * 15))
        
        return {
            'score': score,
            'numeros_encontrados': numeros,
            'especificidade': especificidade,
            'dados_utilizados': len(dados_utilizados)
        }
    except Exception as e:
        logger.error(f"Erro ao calcular qualidade: {str(e)}")
        return {'score': 50, 'numeros_encontrados': 0, 'especificidade': 0, 'dados_utilizados': 0}

# Configura√ß√£o da p√°gina Streamlit
st.set_page_config(page_title="Assistente de An√°lise de Dados", layout="wide")
st.title("Assistente de An√°lise de Dados")

# Estado da sess√£o
if 'dados_processados' not in st.session_state:
    st.session_state.dados_processados = None
if 'historico_chat' not in st.session_state:
    st.session_state.historico_chat = []
if 'estatisticas_qualidade' not in st.session_state:
    st.session_state.estatisticas_qualidade = {
        'total_respostas': 0,
        'score_medio': 0,
        'melhor_score': 0,
        'tipos_analise': {}
    }

# Upload de arquivo ZIP
arquivo_zip = st.file_uploader("Fa√ßa upload do arquivo ZIP contendo seus arquivos CSV", type=['zip'])

if arquivo_zip is not None and st.session_state.dados_processados is None:
    with st.spinner('Processando arquivos com valida√ß√£o Pydantic...'):
        st.session_state.dados_processados = processar_arquivo_zip(arquivo_zip)
    
    if st.session_state.dados_processados:
        st.success(f'‚úÖ {st.session_state.dados_processados.total_arquivos} arquivo(s) processado(s) com sucesso!')
        
        # Valida√ß√£o de integridade
        st.subheader("üîç Valida√ß√£o de Integridade")
        validacoes = validar_integridade_dados(st.session_state.dados_processados)
        for validacao in validacoes:
            st.write(validacao)
        
        # Mostrar resumo dos arquivos processados
        st.subheader("üìÅ Arquivos processados")
        for arquivo, dados in st.session_state.dados_processados.arquivos.items():
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Arquivo", arquivo)
            with col2:
                st.metric("Registros", dados.total_registros)
            with col3:
                st.metric("Colunas", len(dados.colunas))
            
            with st.expander(f"Detalhes de {arquivo}"):
                st.json({col: str(tipo) for col, tipo in dados.tipos_dados.items()})

        # Mostrar dados carregados
        with st.expander("üìä Visualizar dados carregados"):
            for nome, dados in st.session_state.dados_processados.arquivos.items():
                st.write(f"**Arquivo:** {nome}")
                st.dataframe(pd.DataFrame(dados.registros).head(10))

        # Bot√£o de resumo estat√≠stico
        if st.button("üìà Gerar resumo estat√≠stico"):
            for nome, dados in st.session_state.dados_processados.arquivos.items():
                df = pd.DataFrame(dados.registros)
                st.write(f"**Resumo estat√≠stico de {nome}**")
                st.write(df.describe(include='all'))
        
        # Exportar dados validados
        if st.button("üíæ Exportar dados validados (JSON)"):
            dados_json = exportar_dados_validados(st.session_state.dados_processados)
            if dados_json:
                st.download_button(
                    label="üì• Download JSON",
                    data=dados_json,
                    file_name=f"dados_validados_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )
            else:
                st.error("Erro ao exportar dados")
    else:
        st.error("‚ùå Erro no processamento dos arquivos")

# √Årea de chat
if st.session_state.dados_processados is not None:
    st.subheader("üí¨ Chat com o Assistente")

    # Dicas para perguntas objetivas
    with st.expander("üí° Dicas para Perguntas Mais Objetivas"):
        st.write("""
        **Para obter respostas mais precisas, tente perguntas como:**
        
        üìä **An√°lises Estat√≠sticas:**
        - "Qual √© a m√©dia de [coluna]?"
        - "Calcule a mediana de [coluna]"
        - "Qual √© o desvio padr√£o de [coluna]?"
        
        üìà **An√°lises de Tend√™ncias:**
        - "Existe alguma tend√™ncia em [coluna]?"
        - "Como [coluna] evolui ao longo do tempo?"
        - "Identifique padr√µes em [coluna]"
        
        ‚öñÔ∏è **Compara√ß√µes:**
        - "Compare [coluna1] com [coluna2]"
        - "Qual √© maior: [valor1] ou [valor2]?"
        - "Diferen√ßas entre [grupo1] e [grupo2]"
        
        **Evite perguntas vagas como:**
        - "Analise os dados" ‚ùå
        - "O que voc√™ acha?" ‚ùå
        - "Tem algo interessante?" ‚ùå
        """)

    # Mostrar estat√≠sticas de qualidade
    if st.session_state.estatisticas_qualidade['total_respostas'] > 0:
        with st.expander("üìä Estat√≠sticas de Qualidade das Respostas"):
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total de Respostas", st.session_state.estatisticas_qualidade['total_respostas'])
            with col2:
                st.metric("Score M√©dio", f"{st.session_state.estatisticas_qualidade['score_medio']:.1f}/100")
            with col3:
                st.metric("Melhor Score", f"{st.session_state.estatisticas_qualidade['melhor_score']:.1f}/100")
            with col4:
                tipos = st.session_state.estatisticas_qualidade['tipos_analise']
                if tipos:
                    tipo_mais_usado = max(tipos, key=tipos.get)
                    st.metric("Tipo Mais Usado", tipo_mais_usado.title())

    # Hist√≥rico de mensagens
    for msg in st.session_state.historico_chat:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # Entrada do usu√°rio
    prompt = st.chat_input("Digite sua pergunta sobre os dados...")

    if prompt:
        st.session_state.historico_chat.append({"role": "user", "content": prompt})
        with st.chat_message("assistant"):
            with st.spinner('Analisando com valida√ß√£o Pydantic...'):
                resposta = gerar_resposta(prompt, st.session_state.dados_processados.arquivos)
                st.write(resposta)
                st.session_state.historico_chat.append({"role": "assistant", "content": resposta})
                
                # Atualizar estat√≠sticas de qualidade
                try:
                    # Extrair score da resposta
                    import re
                    score_match = re.search(r'Score:\s*(\d+)/100', resposta)
                    if score_match:
                        score = int(score_match.group(1))
                        tipo_match = re.search(r'Tipo de An√°lise:\s*(\w+)', resposta)
                        tipo = tipo_match.group(1).lower() if tipo_match else "geral"
                        
                        # Atualizar estat√≠sticas
                        stats = st.session_state.estatisticas_qualidade
                        stats['total_respostas'] += 1
                        stats['score_medio'] = ((stats['score_medio'] * (stats['total_respostas'] - 1)) + score) / stats['total_respostas']
                        stats['melhor_score'] = max(stats['melhor_score'], score)
                        stats['tipos_analise'][tipo] = stats['tipos_analise'].get(tipo, 0) + 1
                        
                except Exception as e:
                    logger.error(f"Erro ao atualizar estat√≠sticas: {str(e)}")
else:
    st.info("üìÅ Envie um arquivo ZIP contendo arquivos CSV para iniciar a an√°lise.")

# Sidebar
with st.sidebar:
    st.subheader("ü§ñ Sobre o Assistente")
    st.write("""
    Este assistente pode ajudar voc√™ a:
    - üìä Analisar arquivos CSV com valida√ß√£o Pydantic
    - üîç Identificar padr√µes nos dados
    - üìà Realizar c√°lculos estat√≠sticos
    - üí¨ Responder perguntas sobre os dados com IA
    - ‚úÖ Validar integridade dos dados
    - üíæ Exportar dados estruturados
    - üéØ Gerar respostas objetivas e precisas
    """)

    st.subheader("üõ°Ô∏è Valida√ß√µes Implementadas")
    st.write("""
    **Pydantic Models:**
    - ‚úÖ Valida√ß√£o de estrutura de dados
    - ‚úÖ Verifica√ß√£o de tipos de dados
    - ‚úÖ Controle de integridade
    - ‚úÖ Timestamps autom√°ticos
    - ‚úÖ Logging de erros
    """)

    st.subheader("üéØ Sistema de Prompts Estruturados")
    st.write("""
    **Tipos de An√°lise:**
    - üìä **Estat√≠stica:** M√©dias, medianas, correla√ß√µes
    - üìà **Tend√™ncias:** Padr√µes e evolu√ß√µes
    - ‚öñÔ∏è **Compara√ß√µes:** Diferen√ßas e rankings
    - üìã **Geral:** An√°lises customizadas
    
    **Benef√≠cios:**
    - üéØ Respostas mais objetivas
    - üìä M√©tricas de qualidade
    - ‚ö° Respostas mais r√°pidas
    - üîç Maior precis√£o
    """)

    if st.session_state.dados_processados is not None:
        st.subheader("üìä Estat√≠sticas")
        st.metric("Arquivos", st.session_state.dados_processados.total_arquivos)
        st.metric("Total de Registros", sum(d.total_registros for d in st.session_state.dados_processados.arquivos.values()))
        
        if st.button("üóëÔ∏è Limpar Dados"):
            st.session_state.dados_processados = None
            st.session_state.historico_chat = []
            st.session_state.estatisticas_qualidade = {
                'total_respostas': 0,
                'score_medio': 0,
                'melhor_score': 0,
                'tipos_analise': {}
            }
            st.rerun()
