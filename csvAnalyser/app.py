import streamlit as st
import google.generativeai as genai
from dotenv import load_dotenv
import os
import json
import pandas as pd
from zipfile import ZipFile
import io
from pydantic import BaseModel, Field, validator
from typing import Dict, List, Any, Optional
from datetime import datetime
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Modelos Pydantic para validaÃ§Ã£o de dados
class DadosCSV(BaseModel):
    """Modelo para validaÃ§Ã£o de dados CSV"""
    nome_arquivo: str
    registros: List[Dict[str, Any]]
    total_registros: int
    colunas: List[str]
    tipos_dados: Dict[str, str]
    timestamp_processamento: datetime = Field(default_factory=datetime.now)
    
    @validator('registros')
    def validar_registros(cls, v):
        if not v:
            raise ValueError('Lista de registros nÃ£o pode estar vazia')
        return v
    
    @validator('total_registros')
    def validar_total_registros(cls, v, values):
        if 'registros' in values and v != len(values['registros']):
            raise ValueError('Total de registros nÃ£o corresponde ao nÃºmero real de registros')
        return v

class AnaliseDados(BaseModel):
    """Modelo para estruturaÃ§Ã£o da anÃ¡lise de dados"""
    pergunta_usuario: str
    interpretacao: str
    dados_analisados: List[str]
    calculos_realizados: List[str]
    resultado: str
    confianca: float = Field(ge=0.0, le=1.0)
    timestamp_analise: datetime = Field(default_factory=datetime.now)
    
    @validator('confianca')
    def validar_confianca(cls, v):
        if not 0.0 <= v <= 1.0:
            raise ValueError('ConfianÃ§a deve estar entre 0.0 e 1.0')
        return v

class DadosProcessados(BaseModel):
    """Modelo para validaÃ§Ã£o dos dados processados"""
    arquivos: Dict[str, DadosCSV]
    total_arquivos: int
    timestamp_processamento: datetime = Field(default_factory=datetime.now)
    
    @validator('total_arquivos')
    def validar_total_arquivos(cls, v, values):
        if 'arquivos' in values and v != len(values['arquivos']):
            raise ValueError('Total de arquivos nÃ£o corresponde ao nÃºmero real de arquivos')
        return v

# Carregar variÃ¡veis de ambiente
load_dotenv()

# Configurar o Gemini
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
genai.configure(api_key=GOOGLE_API_KEY)

# Configurar o modelo
model = genai.GenerativeModel('gemini-2.0-flash')

# Sistema de prompts estruturados para respostas mais objetivas
class SistemaPrompts:
    """Sistema de prompts estruturados para anÃ¡lises mais objetivas"""
    
    @staticmethod
    def prompt_analise_estatistica():
        return """
        VocÃª Ã© um analista de dados especializado. Responda de forma OBJETIVA e PRECISA.
        
        ESTRUTURA OBRIGATÃ“RIA da resposta:
        
        ## ğŸ“Š ANÃLISE ESTATÃSTICA
        
        **Pergunta:** [pergunta do usuÃ¡rio]
        
        **Dados Analisados:** [arquivos e registros utilizados]
        
        **MÃ©tricas Encontradas:**
        - [mÃ©trica 1]: [valor numÃ©rico]
        - [mÃ©trica 2]: [valor numÃ©rico]
        
        **ConclusÃ£o:** [resposta direta e objetiva em 1-2 frases]
        
        **ConfianÃ§a:** [0-100%] - [justificativa breve]
        
        REGRAS:
        - Use APENAS dados fornecidos
        - Seja CONCISO e DIRETO
        - Evite linguagem vaga
        - Sempre forneÃ§a valores numÃ©ricos quando possÃ­vel
        - MÃ¡ximo 3 parÃ¡grafos
        """
    
    @staticmethod
    def prompt_analise_tendencia():
        return """
        VocÃª Ã© um analista de tendÃªncias. Identifique padrÃµes de forma OBJETIVA.
        
        ESTRUTURA OBRIGATÃ“RIA:
        
        ## ğŸ“ˆ ANÃLISE DE TENDÃŠNCIAS
        
        **PadrÃ£o Identificado:** [descriÃ§Ã£o clara do padrÃ£o]
        
        **EvidÃªncias:**
        - [evidÃªncia 1 com dados]
        - [evidÃªncia 2 com dados]
        
        **ForÃ§a da TendÃªncia:** [Forte/MÃ©dia/Fraca] - [justificativa]
        
        **ConclusÃ£o:** [resposta direta]
        
        REGRAS:
        - Baseie-se APENAS nos dados
        - Quantifique quando possÃ­vel
        - Seja especÃ­fico sobre a forÃ§a da tendÃªncia
        """
    
    @staticmethod
    def prompt_comparacao():
        return """
        VocÃª Ã© um analista comparativo. Compare dados de forma OBJETIVA.
        
        ESTRUTURA OBRIGATÃ“RIA:
        
        ## âš–ï¸ ANÃLISE COMPARATIVA
        
        **ComparaÃ§Ã£o:** [o que estÃ¡ sendo comparado]
        
        **DiferenÃ§as Principais:**
        1. [diferenÃ§a 1 com valores]
        2. [diferenÃ§a 2 com valores]
        
        **ConclusÃ£o:** [qual Ã© melhor/maior/menor e por quÃª]
        
        **SignificÃ¢ncia:** [Alta/MÃ©dia/Baixa] - [justificativa]
        
        REGRAS:
        - Sempre forneÃ§a valores comparativos
        - Evite opiniÃµes pessoais
        - Use dados quantitativos
        """

# FunÃ§Ã£o para processar arquivos CSV dentro de um ZIP com validaÃ§Ã£o Pydantic
def processar_arquivo_zip(arquivo_zip):
    """
    Processa arquivos CSV dentro de um ZIP com validaÃ§Ã£o usando Pydantic
    """
    try:
        dados_arquivos = {}
        
        with ZipFile(arquivo_zip) as zip_file:
            arquivos_csv = [f for f in zip_file.namelist() if f.endswith('.csv')]
            
            if not arquivos_csv:
                raise ValueError("Nenhum arquivo CSV encontrado no ZIP")
            
            for arquivo in arquivos_csv:
                try:
                    with zip_file.open(arquivo) as csv_file:
                        df = pd.read_csv(csv_file)
                        
                        # Limitar a 1000 registros para performance
                        if len(df) > 1000:
                            df = df.sample(1000, random_state=42)
                            logger.info(f"Arquivo {arquivo} limitado a 1000 registros")
                        
                        # Criar instÃ¢ncia validada do modelo DadosCSV
                        dados_csv = DadosCSV(
                            nome_arquivo=arquivo,
                            registros=df.to_dict(orient='records'),
                            total_registros=len(df),
                            colunas=df.columns.tolist(),
                            tipos_dados=df.dtypes.astype(str).to_dict()
                        )
                        
                        dados_arquivos[arquivo] = dados_csv
                        logger.info(f"Arquivo {arquivo} processado com sucesso: {len(df)} registros")
                        
                except Exception as e:
                    logger.error(f"Erro ao processar arquivo {arquivo}: {str(e)}")
                    st.error(f"Erro ao processar {arquivo}: {str(e)}")
                    continue
        
        # Criar instÃ¢ncia validada do modelo DadosProcessados
        dados_processados = DadosProcessados(
            arquivos=dados_arquivos,
            total_arquivos=len(dados_arquivos)
        )
        
        logger.info(f"Processamento concluÃ­do: {len(dados_arquivos)} arquivos processados")
        return dados_processados
        
    except Exception as e:
        logger.error(f"Erro geral no processamento: {str(e)}")
        st.error(f"Erro no processamento: {str(e)}")
        return None

# FunÃ§Ã£o para gerar resposta baseada nos dados e na pergunta com validaÃ§Ã£o Pydantic
def gerar_resposta(prompt, dados_contexto):
    """
    Gera resposta estruturada usando Pydantic para validaÃ§Ã£o e prompts especÃ­ficos para objetividade
    """
    try:
        # Preparar dados para o contexto
        dados_para_analise = {}
        for nome_arquivo, dados_csv in dados_contexto.items():
            dados_para_analise[nome_arquivo] = {
                'registros': dados_csv.registros,
                'colunas': dados_csv.colunas,
                'tipos_dados': dados_csv.tipos_dados,
                'total_registros': dados_csv.total_registros
            }
        
        # Classificar o tipo de pergunta
        tipo_pergunta = classificar_pergunta(prompt)
        
        # Selecionar prompt especÃ­fico baseado no tipo de pergunta
        if tipo_pergunta == "estatistica":
            instrucao = SistemaPrompts.prompt_analise_estatistica()
        elif tipo_pergunta == "tendencia":
            instrucao = SistemaPrompts.prompt_analise_tendencia()
        elif tipo_pergunta == "comparacao":
            instrucao = SistemaPrompts.prompt_comparacao()
        else:
            instrucao = """
            VocÃª Ã© um analista de dados especializado. Responda de forma OBJETIVA e PRECISA.
            
            ESTRUTURA OBRIGATÃ“RIA:
            
            ## ğŸ“Š ANÃLISE DE DADOS
            
            **Pergunta:** [pergunta do usuÃ¡rio]
            
            **Dados Analisados:** [arquivos e registros utilizados]
            
            **AnÃ¡lise:** [resposta direta e objetiva]
            
            **ConclusÃ£o:** [resumo em 1 frase]
            
            **ConfianÃ§a:** [0-100%]
            
            REGRAS:
            - Use APENAS dados fornecidos
            - Seja CONCISO e DIRETO
            - Evite linguagem vaga
            - Sempre forneÃ§a valores numÃ©ricos quando possÃ­vel
            """
        
        contexto = f"{instrucao}\n\nDADOS DISPONÃVEIS: {json.dumps(dados_para_analise, ensure_ascii=False)}\n\nPERGUNTA: {prompt}"
        
        resposta = model.generate_content(contexto)
        
        # Calcular mÃ©tricas de qualidade
        qualidade = calcular_qualidade_resposta(resposta.text, dados_contexto)
        
        # Tentar estruturar a resposta usando Pydantic
        try:
            analise_estruturada = AnaliseDados(
                pergunta_usuario=prompt,
                interpretacao=f"AnÃ¡lise {tipo_pergunta} baseada em {len(dados_contexto)} arquivo(s)",
                dados_analisados=list(dados_contexto.keys()),
                calculos_realizados=[f"AnÃ¡lise {tipo_pergunta}", "ValidaÃ§Ã£o Pydantic"],
                resultado=resposta.text,
                confianca=qualidade['score'] / 100.0
            )
            
            # Retornar resposta estruturada com mÃ©tricas de qualidade
            return f"""
{analise_estruturada.resultado}

---
**ğŸ“Š MÃ©tricas de Qualidade:**
- **Score:** {qualidade['score']}/100
- **NÃºmeros Encontrados:** {qualidade['numeros_encontrados']}
- **Especificidade:** {qualidade['especificidade']}/6
- **Tipo de AnÃ¡lise:** {tipo_pergunta.title()}
- **Timestamp:** {analise_estruturada.timestamp_analise.strftime('%d/%m/%Y %H:%M:%S')}
            """
            
        except Exception as e:
            logger.warning(f"NÃ£o foi possÃ­vel estruturar a resposta: {str(e)}")
            return f"""
{resposta.text}

---
**ğŸ“Š MÃ©tricas de Qualidade:**
- **Score:** {qualidade['score']}/100
- **NÃºmeros Encontrados:** {qualidade['numeros_encontrados']}
- **Especificidade:** {qualidade['especificidade']}/6
- **Tipo de AnÃ¡lise:** {tipo_pergunta.title()}
            """
            
    except Exception as e:
        logger.error(f"Erro ao gerar resposta: {str(e)}")
        return f"Erro ao processar sua pergunta: {str(e)}"

# FunÃ§Ã£o para exportar dados validados em JSON
def exportar_dados_validados(dados_processados):
    """
    Exporta dados processados em formato JSON estruturado
    """
    try:
        dados_export = {
            "metadata": {
                "total_arquivos": dados_processados.total_arquivos,
                "timestamp_processamento": dados_processados.timestamp_processamento.isoformat(),
                "versao": "1.0"
            },
            "arquivos": {}
        }
        
        for nome_arquivo, dados_csv in dados_processados.arquivos.items():
            dados_export["arquivos"][nome_arquivo] = {
                "nome_arquivo": dados_csv.nome_arquivo,
                "total_registros": dados_csv.total_registros,
                "colunas": dados_csv.colunas,
                "tipos_dados": dados_csv.tipos_dados,
                "timestamp_processamento": dados_csv.timestamp_processamento.isoformat(),
                "registros": dados_csv.registros[:100]  # Limitar para exportaÃ§Ã£o
            }
        
        return json.dumps(dados_export, ensure_ascii=False, indent=2)
        
    except Exception as e:
        logger.error(f"Erro ao exportar dados: {str(e)}")
        return None

# FunÃ§Ã£o para validar integridade dos dados
def validar_integridade_dados(dados_processados):
    """
    Valida a integridade dos dados processados
    """
    try:
        validacoes = []
        
        for nome_arquivo, dados_csv in dados_processados.arquivos.items():
            # Validar se o nÃºmero de registros estÃ¡ correto
            if len(dados_csv.registros) != dados_csv.total_registros:
                validacoes.append(f"âŒ {nome_arquivo}: InconsistÃªncia no nÃºmero de registros")
            else:
                validacoes.append(f"âœ… {nome_arquivo}: {dados_csv.total_registros} registros vÃ¡lidos")
            
            # Validar se hÃ¡ colunas
            if not dados_csv.colunas:
                validacoes.append(f"âŒ {nome_arquivo}: Nenhuma coluna encontrada")
            else:
                validacoes.append(f"âœ… {nome_arquivo}: {len(dados_csv.colunas)} colunas")
            
            # Validar se hÃ¡ dados
            if not dados_csv.registros:
                validacoes.append(f"âŒ {nome_arquivo}: Nenhum registro encontrado")
            else:
                validacoes.append(f"âœ… {nome_arquivo}: Dados presentes")
        
        return validacoes
        
    except Exception as e:
        logger.error(f"Erro na validaÃ§Ã£o: {str(e)}")
        return [f"âŒ Erro na validaÃ§Ã£o: {str(e)}"]

# FunÃ§Ã£o para classificar o tipo de pergunta
def classificar_pergunta(prompt):
    """
    Classifica o tipo de pergunta para usar o prompt mais adequado
    """
    prompt_lower = prompt.lower()
    
    # Palavras-chave para diferentes tipos de anÃ¡lise
    estatisticas = ['mÃ©dia', 'mediana', 'moda', 'desvio', 'padrÃ£o', 'percentil', 'quartil', 'correlaÃ§Ã£o']
    tendencias = ['tendÃªncia', 'padrÃ£o', 'crescimento', 'diminuiÃ§Ã£o', 'evoluÃ§Ã£o', 'comportamento']
    comparacoes = ['comparar', 'diferenÃ§a', 'maior', 'menor', 'melhor', 'pior', 'versus', 'vs']
    
    if any(palavra in prompt_lower for palavra in estatisticas):
        return "estatistica"
    elif any(palavra in prompt_lower for palavra in tendencias):
        return "tendencia"
    elif any(palavra in prompt_lower for palavra in comparacoes):
        return "comparacao"
    else:
        return "geral"

# FunÃ§Ã£o para calcular mÃ©tricas de qualidade da resposta
def calcular_qualidade_resposta(resposta, dados_utilizados):
    """
    Calcula mÃ©tricas de qualidade da resposta
    """
    try:
        # Contar nÃºmeros na resposta (indicador de precisÃ£o)
        import re
        numeros = len(re.findall(r'\d+\.?\d*', resposta))
        
        # Contar palavras especÃ­ficas de dados
        palavras_dados = ['mÃ©dia', 'mediana', 'total', 'percentual', 'correlaÃ§Ã£o', 'tendÃªncia']
        especificidade = sum(1 for palavra in palavras_dados if palavra.lower() in resposta.lower())
        
        # Calcular score de qualidade (0-100)
        score = min(100, (numeros * 10) + (especificidade * 15))
        
        return {
            'score': score,
            'numeros_encontrados': numeros,
            'especificidade': especificidade,
            'dados_utilizados': len(dados_utilizados)
        }
    except Exception as e:
        logger.error(f"Erro ao calcular qualidade: {str(e)}")
        return {'score': 50, 'numeros_encontrados': 0, 'especificidade': 0, 'dados_utilizados': 0}

# ConfiguraÃ§Ã£o da pÃ¡gina Streamlit
st.set_page_config(page_title="Assistente de AnÃ¡lise de Dados", layout="wide")
st.title("Assistente de AnÃ¡lise de Dados")

# Estado da sessÃ£o
if 'dados_processados' not in st.session_state:
    st.session_state.dados_processados = None
if 'historico_chat' not in st.session_state:
    st.session_state.historico_chat = []
if 'estatisticas_qualidade' not in st.session_state:
    st.session_state.estatisticas_qualidade = {
        'total_respostas': 0,
        'score_medio': 0,
        'melhor_score': 0,
        'tipos_analise': {}
    }

# Upload de arquivo ZIP
arquivo_zip = st.file_uploader("FaÃ§a upload do arquivo ZIP contendo seus arquivos CSV", type=['zip'])

if arquivo_zip is not None and st.session_state.dados_processados is None:
    with st.spinner('Processando arquivos com validaÃ§Ã£o Pydantic...'):
        st.session_state.dados_processados = processar_arquivo_zip(arquivo_zip)
    
    if st.session_state.dados_processados:
        st.success(f'âœ… {st.session_state.dados_processados.total_arquivos} arquivo(s) processado(s) com sucesso!')
        
        # ValidaÃ§Ã£o de integridade
        st.subheader("ğŸ” ValidaÃ§Ã£o de Integridade")
        validacoes = validar_integridade_dados(st.session_state.dados_processados)
        for validacao in validacoes:
            st.write(validacao)
        
        # Mostrar resumo dos arquivos processados
        st.subheader("ğŸ“ Arquivos processados")
        for arquivo, dados in st.session_state.dados_processados.arquivos.items():
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Arquivo", arquivo)
            with col2:
                st.metric("Registros", dados.total_registros)
            with col3:
                st.metric("Colunas", len(dados.colunas))
            
            with st.expander(f"Detalhes de {arquivo}"):
                st.json({col: str(tipo) for col, tipo in dados.tipos_dados.items()})

        # Mostrar dados carregados
        with st.expander("ğŸ“Š Visualizar dados carregados"):
            for nome, dados in st.session_state.dados_processados.arquivos.items():
                st.write(f"**Arquivo:** {nome}")
                st.dataframe(pd.DataFrame(dados.registros).head(10))

        # BotÃ£o de resumo estatÃ­stico
        if st.button("ğŸ“ˆ Gerar resumo estatÃ­stico"):
            for nome, dados in st.session_state.dados_processados.arquivos.items():
                df = pd.DataFrame(dados.registros)
                st.write(f"**Resumo estatÃ­stico de {nome}**")
                st.write(df.describe(include='all'))
        
        # Exportar dados validados
        if st.button("ğŸ’¾ Exportar dados validados (JSON)"):
            dados_json = exportar_dados_validados(st.session_state.dados_processados)
            if dados_json:
                st.download_button(
                    label="ğŸ“¥ Download JSON",
                    data=dados_json,
                    file_name=f"dados_validados_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )
            else:
                st.error("Erro ao exportar dados")
    else:
        st.error("âŒ Erro no processamento dos arquivos")

# Ãrea de chat
if st.session_state.dados_processados is not None:
    st.subheader("ğŸ’¬ Chat com o Assistente")

    # Dicas para perguntas objetivas
    with st.expander("ğŸ’¡ Dicas para Perguntas Mais Objetivas"):
        st.write("""
        **Para obter respostas mais precisas, tente perguntas como:**
        
        ğŸ“Š **AnÃ¡lises EstatÃ­sticas:**
        - "Qual Ã© a mÃ©dia de [coluna]?"
        - "Calcule a mediana de [coluna]"
        - "Qual Ã© o desvio padrÃ£o de [coluna]?"
        
        ğŸ“ˆ **AnÃ¡lises de TendÃªncias:**
        - "Existe alguma tendÃªncia em [coluna]?"
        - "Como [coluna] evolui ao longo do tempo?"
        - "Identifique padrÃµes em [coluna]"
        
        âš–ï¸ **ComparaÃ§Ãµes:**
        - "Compare [coluna1] com [coluna2]"
        - "Qual Ã© maior: [valor1] ou [valor2]?"
        - "DiferenÃ§as entre [grupo1] e [grupo2]"
        
        **Evite perguntas vagas como:**
        - "Analise os dados" âŒ
        - "O que vocÃª acha?" âŒ
        - "Tem algo interessante?" âŒ
        """)

    # Mostrar estatÃ­sticas de qualidade
    if st.session_state.estatisticas_qualidade['total_respostas'] > 0:
        with st.expander("ğŸ“Š EstatÃ­sticas de Qualidade das Respostas"):
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total de Respostas", st.session_state.estatisticas_qualidade['total_respostas'])
            with col2:
                st.metric("Score MÃ©dio", f"{st.session_state.estatisticas_qualidade['score_medio']:.1f}/100")
            with col3:
                st.metric("Melhor Score", f"{st.session_state.estatisticas_qualidade['melhor_score']:.1f}/100")
            with col4:
                tipos = st.session_state.estatisticas_qualidade['tipos_analise']
                if tipos:
                    tipo_mais_usado = max(tipos, key=tipos.get)
                    st.metric("Tipo Mais Usado", tipo_mais_usado.title())

    # HistÃ³rico de mensagens
    for msg in st.session_state.historico_chat:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # Entrada do usuÃ¡rio
    prompt = st.chat_input("Digite sua pergunta sobre os dados...")

    if prompt:
        st.session_state.historico_chat.append({"role": "user", "content": prompt})
        with st.chat_message("assistant"):
            with st.spinner('Analisando com validaÃ§Ã£o Pydantic...'):
                resposta = gerar_resposta(prompt, st.session_state.dados_processados.arquivos)
                st.write(resposta)
                st.session_state.historico_chat.append({"role": "assistant", "content": resposta})
                
                # Atualizar estatÃ­sticas de qualidade
                try:
                    # Extrair score da resposta
                    import re
                    score_match = re.search(r'Score:\s*(\d+)/100', resposta)
                    if score_match:
                        score = int(score_match.group(1))
                        tipo_match = re.search(r'Tipo de AnÃ¡lise:\s*(\w+)', resposta)
                        tipo = tipo_match.group(1).lower() if tipo_match else "geral"
                        
                        # Atualizar estatÃ­sticas
                        stats = st.session_state.estatisticas_qualidade
                        stats['total_respostas'] += 1
                        stats['score_medio'] = ((stats['score_medio'] * (stats['total_respostas'] - 1)) + score) / stats['total_respostas']
                        stats['melhor_score'] = max(stats['melhor_score'], score)
                        stats['tipos_analise'][tipo] = stats['tipos_analise'].get(tipo, 0) + 1
                        
                except Exception as e:
                    logger.error(f"Erro ao atualizar estatÃ­sticas: {str(e)}")
else:
    st.info("ğŸ“ Envie um arquivo ZIP contendo arquivos CSV para iniciar a anÃ¡lise.")

# Sidebar
with st.sidebar:
    st.subheader("ğŸ¤– Sobre o Assistente")
    st.write("""
    Este assistente pode ajudar vocÃª a:
    - ğŸ“Š Analisar arquivos CSV com validaÃ§Ã£o Pydantic
    - ğŸ” Identificar padrÃµes nos dados
    - ğŸ“ˆ Realizar cÃ¡lculos estatÃ­sticos
    - ğŸ’¬ Responder perguntas sobre os dados com IA
    - âœ… Validar integridade dos dados
    - ğŸ’¾ Exportar dados estruturados
    - ğŸ¯ Gerar respostas objetivas e precisas
    """)

    st.subheader("ğŸ›¡ï¸ ValidaÃ§Ãµes Implementadas")
    st.write("""
    **Pydantic Models:**
    - âœ… ValidaÃ§Ã£o de estrutura de dados
    - âœ… VerificaÃ§Ã£o de tipos de dados
    - âœ… Controle de integridade
    - âœ… Timestamps automÃ¡ticos
    - âœ… Logging de erros
    """)

    st.subheader("ğŸ¯ Sistema de Prompts Estruturados")
    st.write("""
    **Tipos de AnÃ¡lise:**
    - ğŸ“Š **EstatÃ­stica:** MÃ©dias, medianas, correlaÃ§Ãµes
    - ğŸ“ˆ **TendÃªncias:** PadrÃµes e evoluÃ§Ãµes
    - âš–ï¸ **ComparaÃ§Ãµes:** DiferenÃ§as e rankings
    - ğŸ“‹ **Geral:** AnÃ¡lises customizadas
    
    **BenefÃ­cios:**
    - ğŸ¯ Respostas mais objetivas
    - ğŸ“Š MÃ©tricas de qualidade
    - âš¡ Respostas mais rÃ¡pidas
    - ğŸ” Maior precisÃ£o
    """)

    if st.session_state.dados_processados is not None:
        st.subheader("ğŸ“Š EstatÃ­sticas")
        st.metric("Arquivos", st.session_state.dados_processados.total_arquivos)
        st.metric("Total de Registros", sum(d.total_registros for d in st.session_state.dados_processados.arquivos.values()))
        
        if st.button("ğŸ—‘ï¸ Limpar Dados"):
            st.session_state.dados_processados = None
            st.session_state.historico_chat = []
            st.session_state.estatisticas_qualidade = {
                'total_respostas': 0,
                'score_medio': 0,
                'melhor_score': 0,
                'tipos_analise': {}
            }
            st.rerun()
